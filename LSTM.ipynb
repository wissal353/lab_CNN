{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Génération d'une série temporelle synthétique (exemple) ---\n",
        "np.random.seed(42)\n",
        "time = np.arange(0, 2000)\n",
        "series = 0.5 * time + 10 * np.sin(time / 50) + np.random.randn(2000) * 5\n",
        "\n",
        "# --- Séparation train / validation ---\n",
        "split_time = 1500\n",
        "x_train = series[:split_time]\n",
        "x_valid = series[split_time:]\n",
        "\n"
      ],
      "metadata": {
        "id": "4DDcTgDZWCNM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_h8JXveUIIb"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "\n",
        "train_dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "#Pour la validation, on n'effectue pas de shuffle:\n",
        "def windowed_dataset_val(series, window_size, batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "val_dataset = windowed_dataset_val(x_valid, window_size, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def train_and_evaluate(model, train_dataset, val_dataset, epochs=20, optimizer='adam', loss='mse', metrics=['mae']):\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Entraînement\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "\n",
        "    # Évaluation finale sur le dataset de validation\n",
        "    results = model.evaluate(val_dataset)\n",
        "    print(f\"Résultats sur validation: {dict(zip(model.metrics_names, results))}\")\n",
        "    # Sauvegarde automatique\n",
        "    model.save(\"trained_model.h5\")\n",
        "    print(\"Modèle sauvegardé sous le nom : trained_model.h5\")\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "3ZkOGUUoWTMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Définition des modèles\n"
      ],
      "metadata": {
        "id": "eUhxsIKRWnW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modèle MLP**"
      ],
      "metadata": {
        "id": "Hdt6HkCGXEqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_mlp_model(window_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(30, activation=\"relu\", input_shape=[window_shape]),\n",
        "        layers.Dense(10, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "8jCFq-xMWsh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modèle RNN**"
      ],
      "metadata": {
        "id": "Ymu-twR7XHBS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84824719"
      },
      "source": [
        "def create_simple_rnn_model(window_size):\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
        "      tf.keras.layers.SimpleRNN(32),\n",
        "      tf.keras.layers.Dense(1),\n",
        "      tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modèle LSTM**"
      ],
      "metadata": {
        "id": "ynMgCU1TjpP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(window_size):\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 1]),\n",
        "      tf.keras.layers.LSTM(32),\n",
        "      tf.keras.layers.Dense(1),\n",
        "      tf.keras.layers.Lambda(lambda x: x * 100.0) # Example lambda layer\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "0NLlZekdjraO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modèle BSTM**"
      ],
      "metadata": {
        "id": "_c8b9oppjyFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bidirectional_lstm_model(window_size):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True), input_shape=[None, 1]),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "        tf.keras.layers.Dense(1),\n",
        "        tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xtm_Xz7nj18M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modèle GRU**"
      ],
      "metadata": {
        "id": "JVJUV5MSkJup"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0834541b"
      },
      "source": [
        "def create_gru_model(window_size):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 1]),\n",
        "        tf.keras.layers.GRU(32),\n",
        "        tf.keras.layers.Dense(1),\n",
        "        tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ce10807",
        "outputId": "7c34313c-78f9-409b-bc35-cc5b0906b0e4"
      },
      "source": [
        "# Train and evaluate Simple RNN model\n",
        "simple_rnn_model = create_simple_rnn_model(window_size)\n",
        "print(\"\\nTraining Simple RNN model...\")\n",
        "history_simple_rnn = train_and_evaluate(simple_rnn_model, train_dataset, val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Simple RNN model...\n",
            "Epoch 1/20\n",
            "     44/Unknown \u001b[1m4s\u001b[0m 10ms/step - loss: 51307.6250 - mae: 189.1169"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 50354.0117 - mae: 187.3781 - val_loss: 177825.7500 - val_mae: 415.8271\n",
            "Epoch 2/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4575.0386 - mae: 49.0446 - val_loss: 73616.8750 - val_mae: 262.3749\n",
            "Epoch 3/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 901.4067 - mae: 21.3310 - val_loss: 52684.0273 - val_mae: 219.1760\n",
            "Epoch 4/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 351.4254 - mae: 12.8041 - val_loss: 41366.8008 - val_mae: 191.4389\n",
            "Epoch 5/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 746.9627 - mae: 20.7005 - val_loss: 38782.4102 - val_mae: 184.8798\n",
            "Epoch 6/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 185.9915 - mae: 10.2799 - val_loss: 33721.1172 - val_mae: 170.6111\n",
            "Epoch 7/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 86.0310 - mae: 6.8997 - val_loss: 31104.4336 - val_mae: 163.3947\n",
            "Epoch 8/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 115.9825 - mae: 8.6074 - val_loss: 28708.0547 - val_mae: 155.4217\n",
            "Epoch 9/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 65.5796 - mae: 6.4220 - val_loss: 27160.0312 - val_mae: 150.4695\n",
            "Epoch 10/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 62.9608 - mae: 6.3194 - val_loss: 26132.8828 - val_mae: 147.1403\n",
            "Epoch 11/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 97.2424 - mae: 7.7595 - val_loss: 25769.9766 - val_mae: 146.5185\n",
            "Epoch 12/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 78.3499 - mae: 6.8502 - val_loss: 25122.2012 - val_mae: 144.2084\n",
            "Epoch 13/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 58.4691 - mae: 6.0652 - val_loss: 23975.5000 - val_mae: 139.3632\n",
            "Epoch 14/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 123.6453 - mae: 8.9061 - val_loss: 24120.6504 - val_mae: 140.4810\n",
            "Epoch 15/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 106.7785 - mae: 8.0852 - val_loss: 24827.5352 - val_mae: 143.6764\n",
            "Epoch 16/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 130.5762 - mae: 9.2659 - val_loss: 24037.3848 - val_mae: 140.2121\n",
            "Epoch 17/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 73.9365 - mae: 6.8100 - val_loss: 23526.8438 - val_mae: 138.0974\n",
            "Epoch 18/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 83.3979 - mae: 7.3074 - val_loss: 23344.2168 - val_mae: 137.5639\n",
            "Epoch 19/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 65.1229 - mae: 6.4060 - val_loss: 23200.6992 - val_mae: 137.2612\n",
            "Epoch 20/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 52.9892 - mae: 5.8087 - val_loss: 23214.0410 - val_mae: 137.9710\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10742.6367 - mae: 90.2106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats sur validation: {'loss': 23214.041015625, 'compile_metrics': 137.9710235595703}\n",
            "Modèle sauvegardé sous le nom : trained_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c523631f",
        "outputId": "0be22c86-0495-419b-ea14-262ab0bcec79"
      },
      "source": [
        "# Train and evaluate MLP model\n",
        "mlp_model = create_mlp_model(window_size)\n",
        "print(\"Training MLP model...\")\n",
        "history_mlp = train_and_evaluate(mlp_model, train_dataset, val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLP model...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 47990.8633 - mae: 183.6405 - val_loss: 2982.0864 - val_mae: 54.0870\n",
            "Epoch 2/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540.6220 - mae: 17.9326 - val_loss: 82.3684 - val_mae: 7.6084\n",
            "Epoch 3/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.5611 - mae: 5.2453 - val_loss: 41.0292 - val_mae: 5.0642\n",
            "Epoch 4/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 41.1321 - mae: 5.1258 - val_loss: 51.8992 - val_mae: 5.7785\n",
            "Epoch 5/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.4647 - mae: 5.4632 - val_loss: 85.2926 - val_mae: 7.7426\n",
            "Epoch 6/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.8470 - mae: 5.1781 - val_loss: 42.8803 - val_mae: 5.2226\n",
            "Epoch 7/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.3440 - mae: 4.9835 - val_loss: 73.5685 - val_mae: 7.1074\n",
            "Epoch 8/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.5376 - mae: 4.9817 - val_loss: 48.8103 - val_mae: 5.6067\n",
            "Epoch 9/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.3603 - mae: 5.3066 - val_loss: 43.1749 - val_mae: 5.2402\n",
            "Epoch 10/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.8601 - mae: 5.1937 - val_loss: 84.4653 - val_mae: 7.7284\n",
            "Epoch 11/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.6915 - mae: 5.1126 - val_loss: 31.4852 - val_mae: 4.4686\n",
            "Epoch 12/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.2248 - mae: 4.9593 - val_loss: 109.7362 - val_mae: 9.0889\n",
            "Epoch 13/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.8213 - mae: 5.1291 - val_loss: 33.4658 - val_mae: 4.5435\n",
            "Epoch 14/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.4385 - mae: 5.1679 - val_loss: 34.1776 - val_mae: 4.6949\n",
            "Epoch 15/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.9566 - mae: 5.3294 - val_loss: 31.2450 - val_mae: 4.4324\n",
            "Epoch 16/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.1921 - mae: 5.0228 - val_loss: 53.1677 - val_mae: 5.9076\n",
            "Epoch 17/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 39.3731 - mae: 4.9777 - val_loss: 85.7653 - val_mae: 7.8026\n",
            "Epoch 18/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.1264 - mae: 5.2439 - val_loss: 58.1957 - val_mae: 6.2016\n",
            "Epoch 19/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.5042 - mae: 5.1959 - val_loss: 61.3005 - val_mae: 6.4124\n",
            "Epoch 20/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.3530 - mae: 5.2983 - val_loss: 32.8838 - val_mae: 4.5176\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.6798 - mae: 4.5358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats sur validation: {'loss': 32.88377380371094, 'compile_metrics': 4.5175957679748535}\n",
            "Modèle sauvegardé sous le nom : trained_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b74ef468",
        "outputId": "e9062b3a-8376-495b-c04b-427024eed74c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Train and evaluate LSTM model\n",
        "lstm_model = create_lstm_model(window_size)\n",
        "print(\"\\nTraining LSTM model...\")\n",
        "history_lstm = train_and_evaluate(lstm_model, train_dataset, val_dataset)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'create_lstm_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2381164863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and evaluate LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining LSTM model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_lstm_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5600a67e"
      },
      "source": [
        "# Train and evaluate Bidirectional LSTM model\n",
        "bidirectional_lstm_model = create_bidirectional_lstm_model(window_size)\n",
        "print(\"\\nTraining Bidirectional LSTM model...\")\n",
        "history_bidirectional_lstm = train_and_evaluate(bidirectional_lstm_model, train_dataset, val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ab4a35"
      },
      "source": [
        "# Train and evaluate GRU model\n",
        "gru_model = create_gru_model(window_size)\n",
        "print(\"\\nTraining GRU model...\")\n",
        "history_gru = train_and_evaluate(gru_model, train_dataset, val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}